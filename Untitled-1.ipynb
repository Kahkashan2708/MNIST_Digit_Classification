{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0cbea34",
   "metadata": {},
   "source": [
    "## MNIST Data Clssification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34f8ca0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp38-cp38-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from scikit-learn) (1.24.3)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn)\n",
      "  Downloading scipy-1.10.1-cp38-cp38-win_amd64.whl.metadata (58 kB)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.3.2-cp38-cp38-win_amd64.whl (9.3 MB)\n",
      "   ---------------------------------------- 0.0/9.3 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.3/9.3 MB 7.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.9/9.3 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.3/9.3 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.7/9.3 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.3/9.3 MB 10.1 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.10.1-cp38-cp38-win_amd64.whl (42.2 MB)\n",
      "   ---------------------------------------- 0.0/42.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.4/42.2 MB 12.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 5.0/42.2 MB 11.6 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 7.3/42.2 MB 11.6 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 9.7/42.2 MB 11.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 12.1/42.2 MB 11.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 14.4/42.2 MB 11.2 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 16.8/42.2 MB 11.3 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 18.6/42.2 MB 10.9 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 20.7/42.2 MB 10.8 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 23.1/42.2 MB 10.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 25.4/42.2 MB 10.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 27.3/42.2 MB 10.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 29.4/42.2 MB 10.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 31.7/42.2 MB 10.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 34.3/42.2 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 36.7/42.2 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 39.1/42.2 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  41.4/42.2 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  42.2/42.2 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 42.2/42.2 MB 10.3 MB/s eta 0:00:00\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.3.2 scipy-1.10.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a0b1596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(3)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958ea68f",
   "metadata": {},
   "source": [
    "#### Loading Mnist Dataset from keras.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51d75df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,Y_train),(X_test,Y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8edd0a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7e7dd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (60000, 28, 28) (60000,) \n",
      "Test data shape: (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data shape:\", X_train.shape, Y_train.shape, \"\\nTest data shape:\", X_test.shape, Y_test.shape)   #60000 data with 28x28 size image\n",
    "#gray scale image=1 channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05a43eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  42 118 219 166 118 118   6\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 103 242 254 254 254 254 254  66\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  18 232 254 254 254 254 254 238\n",
      "   70   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 104 244 254 224 254 254 254\n",
      "  141   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 207 254 210 254 254 254\n",
      "   34   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  84 206 254 254 254 254\n",
      "   41   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  24 209 254 254 254\n",
      "  171   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  91 137 253 254 254 254\n",
      "  112   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  40 214 250 254 254 254 254 254\n",
      "   34   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  81 247 254 254 254 254 254 254\n",
      "  146   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 110 246 254 254 254 254 254\n",
      "  171   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  73  89  89  93 240 254\n",
      "  171   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1 128 254\n",
      "  219  31   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   7 254 254\n",
      "  214  28   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 138 254 254\n",
      "  116   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  19 177  90   0   0   0   0   0  25 240 254 254\n",
      "   34   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 164 254 215  63  36   0  51  89 206 254 254 139\n",
      "    8   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  57 197 254 254 222 180 241 254 254 253 213  11\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 140 105 254 254 254 254 254 254 236   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   7 117 117 165 254 254 239  50   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# printing the 10th image\n",
    "print(X_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4b1080c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[10].shape) # shape of Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d5e9430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# displayinng the image to check the dimension and values\n",
    "plt.imshow(X_train[50])\n",
    "plt.show()\n",
    "\n",
    "# print the corresponding label\n",
    "print(Y_train[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b1027d",
   "metadata": {},
   "source": [
    "### Image Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a75ce7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# unique values in Y_train\n",
    "print(np.unique(Y_train))\n",
    "\n",
    "# unique values in Y_test\n",
    "print(np.unique(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a27380d",
   "metadata": {},
   "source": [
    " Since all the images have same dimension in this dataset, so we don't need to resize the dimension of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44421df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scaling or normalising the values\n",
    "\n",
    "X_train=X_train/255  # maximum value is 255\n",
    "X_test= X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fac27a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.16470588\n",
      "  0.4627451  0.85882353 0.65098039 0.4627451  0.4627451  0.02352941\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.40392157 0.94901961\n",
      "  0.99607843 0.99607843 0.99607843 0.99607843 0.99607843 0.25882353\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.07058824 0.90980392\n",
      "  0.99607843 0.99607843 0.99607843 0.99607843 0.99607843 0.93333333\n",
      "  0.2745098  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.40784314\n",
      "  0.95686275 0.99607843 0.87843137 0.99607843 0.99607843 0.99607843\n",
      "  0.55294118 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.81176471 0.99607843 0.82352941 0.99607843 0.99607843 0.99607843\n",
      "  0.13333333 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.32941176 0.80784314 0.99607843 0.99607843 0.99607843 0.99607843\n",
      "  0.16078431 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.09411765 0.81960784 0.99607843 0.99607843 0.99607843\n",
      "  0.67058824 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.35686275 0.5372549  0.99215686 0.99607843 0.99607843 0.99607843\n",
      "  0.43921569 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.15686275 0.83921569\n",
      "  0.98039216 0.99607843 0.99607843 0.99607843 0.99607843 0.99607843\n",
      "  0.13333333 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.31764706 0.96862745\n",
      "  0.99607843 0.99607843 0.99607843 0.99607843 0.99607843 0.99607843\n",
      "  0.57254902 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.43137255\n",
      "  0.96470588 0.99607843 0.99607843 0.99607843 0.99607843 0.99607843\n",
      "  0.67058824 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.28627451 0.34901961 0.34901961 0.36470588 0.94117647 0.99607843\n",
      "  0.67058824 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00392157 0.50196078 0.99607843\n",
      "  0.85882353 0.12156863 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.02745098 0.99607843 0.99607843\n",
      "  0.83921569 0.10980392 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.54117647 0.99607843 0.99607843\n",
      "  0.45490196 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.0745098  0.69411765 0.35294118 0.         0.         0.\n",
      "  0.         0.         0.09803922 0.94117647 0.99607843 0.99607843\n",
      "  0.13333333 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.64313725 0.99607843 0.84313725 0.24705882 0.14117647 0.\n",
      "  0.2        0.34901961 0.80784314 0.99607843 0.99607843 0.54509804\n",
      "  0.03137255 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.22352941 0.77254902 0.99607843 0.99607843 0.87058824 0.70588235\n",
      "  0.94509804 0.99607843 0.99607843 0.99215686 0.83529412 0.04313725\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.54901961 0.41176471 0.99607843 0.99607843 0.99607843\n",
      "  0.99607843 0.99607843 0.99607843 0.9254902  0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.02745098 0.45882353 0.45882353 0.64705882\n",
      "  0.99607843 0.99607843 0.9372549  0.19607843 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# now just check the 10th value of X_train\n",
    "print(X_train[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350bf2c8",
   "metadata": {},
   "source": [
    "Now we can see that all the values are between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a51c72",
   "metadata": {},
   "source": [
    "## Building the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b262b581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the layers of neyral network\n",
    "\n",
    "model=keras.Sequential([\n",
    "                         keras.layers.Flatten(input_shape=(28,28)),\n",
    "                         keras.layers.Dense(50,activation='relu'),\n",
    "                         keras.layers.Dense(50,activation='relu'),\n",
    "                         keras.layers.Dense(10,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42d3e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the neural network\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e30678dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 20s 9ms/step - loss: 0.3071 - accuracy: 0.9110\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1406 - accuracy: 0.9575\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1023 - accuracy: 0.9688\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0821 - accuracy: 0.9747\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0684 - accuracy: 0.9783\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0581 - accuracy: 0.9815\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0492 - accuracy: 0.9837\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0441 - accuracy: 0.9850\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0394 - accuracy: 0.9869\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0343 - accuracy: 0.9887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26ad08115b0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the neural network\n",
    "\n",
    "model.fit(X_train, Y_train,epochs=10)                  # epochs: how many times the neural network go through the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865a4f8f",
   "metadata": {},
   "source": [
    "Accuracy on Training data = 98.87 %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10949fd5",
   "metadata": {},
   "source": [
    "### Accuracy on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5301af92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1047 - accuracy: 0.9716\n",
      "Accuracy on Test Data:  0.9715999960899353\n",
      "Loss:  0.10472594946622849\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy=model.evaluate(X_test,Y_test)\n",
    "print(\"Accuracy on Test Data: \", accuracy)\n",
    "print(\"Loss: \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e88f69a",
   "metadata": {},
   "source": [
    "* Test data accuracy = 97.1599 %\n",
    "* Thus our model is not overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f529b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
